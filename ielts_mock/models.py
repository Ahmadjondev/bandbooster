from django.db import models
from django.contrib.auth.models import User
import uuid
import json
from django.utils import timezone
import logging

logger = logging.getLogger(__name__)

class MockTest(models.Model):
    TEST_TYPE_CHOICES = (
        ('academic', 'Academic'),
        ('general', 'General Training'),
    )

    STATUS_CHOICES = (
        ('not_started', 'Not Started'),
        ('in_progress', 'In Progress'),
        ('completed', 'Completed'),
    )

    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name='mock_tests')
    test_type = models.CharField(max_length=20, choices=TEST_TYPE_CHOICES)
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='not_started')
    created_at = models.DateTimeField(auto_now_add=True)
    started_at = models.DateTimeField(null=True, blank=True)
    completed_at = models.DateTimeField(null=True, blank=True)

    # Test content (generated by GPT)
    reading_content = models.JSONField(null=True, blank=True)
    listening_content = models.JSONField(null=True, blank=True)
    writing_content = models.JSONField(null=True, blank=True)

    # User responses
    reading_responses = models.JSONField(null=True, blank=True)
    listening_responses = models.JSONField(null=True, blank=True)
    writing_responses = models.JSONField(null=True, blank=True)

    # Audio paths for listening section
    audio_paths = models.JSONField(null=True, blank=True)

    # Scores
    reading_score = models.FloatField(null=True, blank=True)
    listening_score = models.FloatField(null=True, blank=True)
    writing_score = models.FloatField(null=True, blank=True)
    speaking_score = models.FloatField(null=True, blank=True)  # For future implementation
    overall_score = models.FloatField(null=True, blank=True)

    # Detailed analysis
    reading_analysis = models.JSONField(null=True, blank=True)
    listening_analysis = models.JSONField(null=True, blank=True)
    writing_analysis = models.JSONField(null=True, blank=True)
    speaking_analysis = models.JSONField(null=True, blank=True)

    # Strengths and weaknesses
    strengths = models.JSONField(null=True, blank=True)
    areas_for_improvement = models.JSONField(null=True, blank=True)

    # Improvement recommendations
    improvement_plan = models.JSONField(null=True, blank=True)

    # Feedback
    feedback = models.JSONField(null=True, blank=True)

    def __str__(self):
        return f"{self.user.username}'s {self.test_type} Test ({self.id})"

    def get_reading_content(self):
        """Get the reading content with proper structure checking"""
        if not self.reading_content:
            return {}

        # If it's a string, parse it as JSON
        if isinstance(self.reading_content, str):
            try:
                content = json.loads(self.reading_content)
            except json.JSONDecodeError:
                logger.error(f"Invalid JSON in reading_content for test {self.id}")
                return {}
        else:
            content = self.reading_content

            # Check if the content has the expected structure
            if 'sections' not in content:
                # Try to adapt the structure if possible
                if 'passages' in content and 'questions' in content:
                    # Old format - convert to new format
                    sections = []
                    for i, passage in enumerate(content.get('passages', [])):
                        section_questions = [q for q in content.get('questions', [])
                                             if q.get('section_number') == passage.get('section')]

                        sections.append({
                            'title': passage.get('title', f'Section {i+1}'),
                            'passage': passage.get('content', ''),
                            'questions': section_questions
                        })

                    return {'sections': sections}
                return {}

            # Handle the format where 'text' is used instead of 'passage'
            for section in content.get('sections', []):
                if 'text' in section and 'passage' not in section:
                    section['passage'] = section.pop('text')

            return content

    def get_listening_content(self):
        return self.listening_content if self.listening_content else {}

    def get_writing_content(self):
        return self.writing_content if self.writing_content else {}

    def get_writing_responses(self):
        """Get the writing responses with proper structure checking"""
        if not self.writing_responses:
            return {}

        # If it's a string, parse it as JSON
        if isinstance(self.writing_responses, str):
            try:
                return json.loads(self.writing_responses)
            except json.JSONDecodeError:
                logger.error(f"Invalid JSON in writing_responses for test {self.id}")
                return {}

        return self.writing_responses

    def save_reading_responses(self, responses):
        self.reading_responses = responses
        self.save()

    def save_listening_responses(self, responses):
        self.listening_responses = responses
        self.save()

    def save_writing_responses(self, responses):
        self.writing_responses = responses
        self.save()

    def analyze_reading_performance(self):
        """Analyze reading performance and identify strengths/weaknesses"""
        if not self.reading_responses or not self.reading_content:
            return {}

        analysis = {
            'total_questions': 0,
            'correct_answers': 0,
            'question_types': {
                'true_false_not_given': {'total': 0, 'correct': 0},
                'multiple_choice': {'total': 0, 'correct': 0},
                'matching': {'total': 0, 'correct': 0},
                'fill_in_blank': {'total': 0, 'correct': 0},
                'other': {'total': 0, 'correct': 0}
            },
            'sections': []
        }

        for section_idx, section in enumerate(self.reading_content.get('sections', [])):
            section_analysis = {
                'title': section.get('title', f'Section {section_idx+1}'),
                'total': 0,
                'correct': 0,
                'questions': []
            }

            for question in section.get('questions', []):
                question_id = str(question.get('id'))
                question_type = question.get('type', 'other')
                answer_value = question.get('answer', '')
                correct_answer = answer_value.lower() if isinstance(answer_value, str) else str(answer_value).lower()
                user_answer_value = self.reading_responses.get(question_id, '')
                user_answer = user_answer_value.lower() if isinstance(user_answer_value, str) else str(user_answer_value).lower()

                # Determine if the answer is correct
                is_correct = user_answer == correct_answer

                # Update overall counters
                analysis['total_questions'] += 1
                if is_correct:
                    analysis['correct_answers'] += 1

                # Update question type counters
                if question_type in analysis['question_types']:
                    analysis['question_types'][question_type]['total'] += 1
                    if is_correct:
                        analysis['question_types'][question_type]['correct'] += 1
                else:
                    analysis['question_types']['other']['total'] += 1
                    if is_correct:
                        analysis['question_types']['other']['correct'] += 1

                # Update section counters
                section_analysis['total'] += 1
                if is_correct:
                    section_analysis['correct'] += 1

                # Add question analysis
                section_analysis['questions'].append({
                    'id': question_id,
                    'type': question_type,
                    'text': question.get('text', ''),
                    'correct_answer': correct_answer,
                    'user_answer': user_answer,
                    'is_correct': is_correct
                })

            analysis['sections'].append(section_analysis)

        # Calculate performance by question type
        for q_type in analysis['question_types']:
            total = analysis['question_types'][q_type]['total']
            correct = analysis['question_types'][q_type]['correct']
            if total > 0:
                analysis['question_types'][q_type]['accuracy'] = round((correct / total) * 100, 1)
            else:
                analysis['question_types'][q_type]['accuracy'] = 0

        # Identify strengths and weaknesses
        strengths = []
        weaknesses = []

        # Check overall performance
        overall_accuracy = analysis['correct_answers'] / analysis['total_questions'] if analysis['total_questions'] > 0 else 0

        if overall_accuracy >= 0.8:
            strengths.append("Good comprehension of main ideas in reading")
        elif overall_accuracy <= 0.5:
            weaknesses.append("General reading comprehension")

        # Check performance by question type
        for q_type, data in analysis['question_types'].items():
            if data['total'] >= 3:  # Only consider if there are enough questions of this type
                accuracy = data['correct'] / data['total']
                if accuracy >= 0.8:
                    if q_type == 'true_false_not_given':
                        strengths.append("Strong at identifying True/False/Not Given statements")
                    elif q_type == 'multiple_choice':
                        strengths.append("Good at selecting correct options in multiple-choice questions")
                    elif q_type == 'matching':
                        strengths.append("Effective at matching information")
                    elif q_type == 'fill_in_blank':
                        strengths.append("Skilled at completing sentences with correct information")
                elif accuracy <= 0.5:
                    if q_type == 'true_false_not_given':
                        weaknesses.append("True/False/Not Given questions in reading")
                    elif q_type == 'multiple_choice':
                        weaknesses.append("Multiple-choice questions in reading")
                    elif q_type == 'matching':
                        weaknesses.append("Matching information in reading")
                    elif q_type == 'fill_in_blank':
                        weaknesses.append("Completing sentences with correct information")

        analysis['strengths'] = strengths
        analysis['weaknesses'] = weaknesses

        return analysis

    def analyze_listening_performance(self):
        """Analyze listening performance and identify strengths/weaknesses"""
        if not self.listening_responses or not self.listening_content:
            return {}

        analysis = {
            'total_questions': 0,
            'correct_answers': 0,
            'question_types': {
                'multiple_choice': {'total': 0, 'correct': 0},
                'fill_in_blank': {'total': 0, 'correct': 0},
                'matching': {'total': 0, 'correct': 0},
                'other': {'total': 0, 'correct': 0}
            },
            'sections': []
        }

        for section_idx, section in enumerate(self.listening_content.get('sections', [])):
            section_analysis = {
                'title': section.get('title', f'Section {section_idx+1}'),
                'description': section.get('description', ''),
                'total': 0,
                'correct': 0,
                'questions': []
            }

            for question in section.get('questions', []):
                question_id = str(question.get('id'))
                question_type = question.get('type', 'other')
                answer_value = question.get('answer', '')
                correct_answer = answer_value.lower() if isinstance(answer_value, str) else str(answer_value).lower()
                user_answer_value = self.listening_responses.get(question_id, '')
                user_answer = user_answer_value.lower() if isinstance(user_answer_value, str) else str(user_answer_value).lower()

                # Determine if the answer is correct
                is_correct = user_answer == correct_answer

                # Update overall counters
                analysis['total_questions'] += 1
                if is_correct:
                    analysis['correct_answers'] += 1

                # Update question type counters
                if question_type in analysis['question_types']:
                    analysis['question_types'][question_type]['total'] += 1
                    if is_correct:
                        analysis['question_types'][question_type]['correct'] += 1
                else:
                    analysis['question_types']['other']['total'] += 1
                    if is_correct:
                        analysis['question_types']['other']['correct'] += 1

                # Update section counters
                section_analysis['total'] += 1
                if is_correct:
                    section_analysis['correct'] += 1

                # Add question analysis
                section_analysis['questions'].append({
                    'id': question_id,
                    'type': question_type,
                    'text': question.get('text', ''),
                    'correct_answer': correct_answer,
                    'user_answer': user_answer,
                    'is_correct': is_correct
                })

            analysis['sections'].append(section_analysis)

        # Calculate performance by question type
        for q_type in analysis['question_types']:
            total = analysis['question_types'][q_type]['total']
            correct = analysis['question_types'][q_type]['correct']
            if total > 0:
                analysis['question_types'][q_type]['accuracy'] = round((correct / total) * 100, 1)
            else:
                analysis['question_types'][q_type]['accuracy'] = 0

        # Identify strengths and weaknesses
        strengths = []
        weaknesses = []

        # Check overall performance
        overall_accuracy = analysis['correct_answers'] / analysis['total_questions'] if analysis['total_questions'] > 0 else 0

        if overall_accuracy >= 0.8:
            strengths.append("Strong note-taking skills in listening")
        elif overall_accuracy <= 0.5:
            weaknesses.append("General listening comprehension")

        # Check performance by question type
        for q_type, data in analysis['question_types'].items():
            if data['total'] >= 3:  # Only consider if there are enough questions of this type
                accuracy = data['correct'] / data['total']
                if accuracy >= 0.8:
                    if q_type == 'multiple_choice':
                        strengths.append("Good at selecting correct options in listening")
                    elif q_type == 'fill_in_blank':
                        strengths.append("Skilled at identifying specific information in listening")
                    elif q_type == 'matching':
                        strengths.append("Effective at matching information in listening")
                elif accuracy <= 0.5:
                    if q_type == 'multiple_choice':
                        weaknesses.append("Multiple-choice questions in listening")
                    elif q_type == 'fill_in_blank':
                        weaknesses.append("Identifying specific information in listening")
                    elif q_type == 'matching':
                        weaknesses.append("Matching information in listening")

        analysis['strengths'] = strengths
        analysis['weaknesses'] = weaknesses

        return analysis

    def analyze_writing_performance(self):
        """Analyze writing performance based on AI feedback"""
        if not self.writing_responses or not self.feedback:
            return {}

        analysis = {
            'task1': {},
            'task2': {},
            'overall': {}
        }

        if 'task1' in self.feedback:
            task1_feedback = self.feedback['task1']
            analysis['task1'] = {
                'task_achievement': task1_feedback.get('task_achievement', 0),
                'coherence_cohesion': task1_feedback.get('coherence_cohesion', 0),
                'lexical_resource': task1_feedback.get('lexical_resource', 0),
                'grammatical_range': task1_feedback.get('grammatical_range', 0),
                'overall_score': task1_feedback.get('overall_score', 0),
                'strengths': task1_feedback.get('strengths', []),
                'improvements': task1_feedback.get('improvements', [])
            }

        if 'task2' in self.feedback:
            task2_feedback = self.feedback['task2']
            analysis['task2'] = {
                'task_achievement': task2_feedback.get('task_achievement', 0),
                'coherence_cohesion': task2_feedback.get('coherence_cohesion', 0),
                'lexical_resource': task2_feedback.get('lexical_resource', 0),
                'grammatical_range': task2_feedback.get('grammatical_range', 0),
                'overall_score': task2_feedback.get('overall_score', 0),
                'strengths': task2_feedback.get('strengths', []),
                'improvements': task2_feedback.get('improvements', [])
            }

        # Identify overall strengths and weaknesses
        strengths = []
        weaknesses = []

        # Check Task 1 performance
        if 'task1' in analysis and analysis['task1']:
            task1 = analysis['task1']

            # Check coherence and cohesion
            if task1.get('coherence_cohesion', 0) >= 7.0:
                strengths.append("Logical structure in writing")
            elif task1.get('coherence_cohesion', 0) <= 5.5:
                weaknesses.append("Organization and coherence in writing")

            # Check lexical resource
            if task1.get('lexical_resource', 0) >= 7.0:
                strengths.append("Good vocabulary range in writing")
            elif task1.get('lexical_resource', 0) <= 5.5:
                weaknesses.append("Limited vocabulary range in writing")

            # Check grammatical range
            if task1.get('grammatical_range', 0) >= 7.0:
                strengths.append("Strong grammatical accuracy in writing")
            elif task1.get('grammatical_range', 0) <= 5.5:
                weaknesses.append("Grammatical errors in writing")

        # Check Task 2 performance
        if 'task2' in analysis and analysis['task2']:
            task2 = analysis['task2']

            # Check task achievement
            if task2.get('task_achievement', 0) >= 7.0:
                strengths.append("Good development of ideas in essays")
            elif task2.get('task_achievement', 0) <= 5.5:
                weaknesses.append("Addressing all parts of essay questions")

        analysis['strengths'] = strengths
        analysis['weaknesses'] = weaknesses

        return analysis

    def generate_improvement_plan(self):
        """Generate a personalized improvement plan based on analysis"""
        plan = {
            'reading': [],
            'listening': [],
            'writing': [],
            'speaking': [],
            'general': []
        }

        # Reading improvement suggestions
        if hasattr(self, 'reading_analysis') and self.reading_analysis:
            weaknesses = self.reading_analysis.get('weaknesses', [])

            if "True/False/Not Given questions in reading" in weaknesses:
                plan['reading'].append({
                    'title': 'Improve True/False/Not Given skills',
                    'description': 'Practice identifying the difference between information that contradicts the text (False) and information that is simply not mentioned (Not Given).',
                    'activities': [
                        'Complete at least 10 True/False/Not Given practice exercises',
                        'Learn to underline key words in statements before searching for them in the text',
                        'Practice paraphrasing to recognize when information is expressed differently'
                    ]
                })

            if "Multiple-choice questions in reading" in weaknesses:
                plan['reading'].append({
                    'title': 'Enhance multiple-choice question strategies',
                    'description': 'Develop techniques to eliminate wrong answers and identify distractors.',
                    'activities': [
                        'Practice reading all options before selecting an answer',
                        'Learn to identify distractors that contain information from the text but don\'t answer the question',
                        'Complete timed multiple-choice exercises to improve speed'
                    ]
                })

            if "General reading comprehension" in weaknesses:
                plan['reading'].append({
                    'title': 'Build overall reading comprehension',
                    'description': 'Improve your ability to understand main ideas and details in complex texts.',
                    'activities': [
                        'Read academic articles for 30 minutes daily',
                        'Practice summarizing paragraphs in your own words',
                        'Create mind maps of texts to visualize relationships between ideas'
                    ]
                })

        # Listening improvement suggestions
        if hasattr(self, 'listening_analysis') and self.listening_analysis:
            weaknesses = self.listening_analysis.get('weaknesses', [])

            if "Multiple-choice questions in listening" in weaknesses:
                plan['listening'].append({
                    'title': 'Improve listening for specific information',
                    'description': 'Develop your ability to identify key details in audio recordings.',
                    'activities': [
                        'Practice note-taking while listening',
                        'Listen for signpost words that indicate important information',
                        'Complete multiple-choice listening exercises with increasing difficulty'
                    ]
                })

            if "Identifying specific information in listening" in weaknesses:
                plan['listening'].append({
                    'title': 'Enhance form completion skills',
                    'description': 'Improve your ability to identify specific details like names, numbers, and dates.',
                    'activities': [
                        'Practice listening for numbers, dates, and proper nouns',
                        'Complete form-filling exercises with audio recordings',
                        'Learn to predict what information might be required before listening'
                    ]
                })

            if "General listening comprehension" in weaknesses:
                plan['listening'].append({
                    'title': 'Build overall listening skills',
                    'description': 'Improve your ability to understand spoken English in various contexts.',
                    'activities': [
                        'Listen to English podcasts or news daily',
                        'Watch English videos with subtitles, then without',
                        'Practice listening to different accents (British, American, Australian)'
                    ]
                })

        # Writing improvement suggestions
        if hasattr(self, 'writing_analysis') and self.writing_analysis:
            weaknesses = self.writing_analysis.get('weaknesses', [])

            if "Limited vocabulary range in writing" in weaknesses:
                plan['writing'].append({
                    'title': 'Expand vocabulary range',
                    'description': 'Develop a broader vocabulary for academic writing.',
                    'activities': [
                        'Learn 10 new academic words weekly',
                        'Practice using synonyms to avoid repetition',
                        'Create a personal vocabulary journal organized by topic'
                    ]
                })

            if "Organization and coherence in writing" in weaknesses:
                plan['writing'].append({
                    'title': 'Improve essay structure',
                    'description': 'Enhance the organization and flow of your writing.',
                    'activities': [
                        'Practice creating detailed essay outlines before writing',
                        'Learn to use a variety of linking words and phrases',
                        'Analyze model essays to understand effective paragraph structure'
                    ]
                })

            if "Grammatical errors in writing" in weaknesses:
                plan['writing'].append({
                    'title': 'Enhance grammatical accuracy',
                    'description': 'Reduce grammatical errors in your writing.',
                    'activities': [
                        'Review one grammar rule daily',
                        'Practice identifying and correcting errors in sample texts',
                        'Keep a log of your common grammar mistakes and review regularly'
                    ]
                })

        # General improvement suggestions
        plan['general'].append({
            'title': 'Develop test-taking strategies',
            'description': 'Improve your overall approach to the IELTS exam.',
            'activities': [
                'Practice time management with full-length mock tests',
                'Learn to quickly identify question types and appropriate strategies',
                'Review and analyze your mistakes after each practice session'
            ]
        })

        return plan

    def calculate_reading_score(self):
        # Logic to calculate reading score based on responses and correct answers
        if not self.reading_responses or not self.reading_content:
            return 0

        correct_count = 0
        total_questions = 0

        for section in self.reading_content.get('sections', []):
            for question in section.get('questions', []):
                question_id = question.get('id')
                correct_answer = question.get('answer')
                user_answer = self.reading_responses.get(str(question_id))

                # Handle both string and non-string answers
                if user_answer:
                    if isinstance(user_answer, str) and isinstance(correct_answer, str):
                        if user_answer.lower() == correct_answer.lower():
                            correct_count += 1
                    else:
                        # For complex answers like dictionaries, compare string representations
                        if str(user_answer).lower() == str(correct_answer).lower():
                            correct_count += 1

                total_questions += 1

        if total_questions == 0:
            return 0

        # Convert to IELTS band score (approximate conversion)
        percentage = correct_count / total_questions
        if percentage >= 0.9: return 9.0
        elif percentage >= 0.85: return 8.5
        elif percentage >= 0.8: return 8.0
        elif percentage >= 0.75: return 7.5
        elif percentage >= 0.7: return 7.0
        elif percentage >= 0.65: return 6.5
        elif percentage >= 0.6: return 6.0
        elif percentage >= 0.55: return 5.5
        elif percentage >= 0.5: return 5.0
        elif percentage >= 0.4: return 4.0
        elif percentage >= 0.3: return 3.0
        else: return 2.0

    def calculate_listening_score(self):
        # Similar logic to reading score calculation
        if not self.listening_responses or not self.listening_content:
            return 0

        correct_count = 0
        total_questions = 0

        for section in self.listening_content.get('sections', []):
            for question in section.get('questions', []):
                question_id = question.get('id')
                correct_answer = question.get('answer')
                user_answer = self.listening_responses.get(str(question_id))

                if user_answer and user_answer.lower() == correct_answer.lower():
                    correct_count += 1

                total_questions += 1

        if total_questions == 0:
            return 0

        # Convert to IELTS band score (approximate conversion)
        percentage = correct_count / total_questions
        if percentage >= 0.9: return 9.0
        elif percentage >= 0.85: return 8.5
        elif percentage >= 0.8: return 8.0
        elif percentage >= 0.75: return 7.5
        elif percentage >= 0.7: return 7.0
        elif percentage >= 0.65: return 6.5
        elif percentage >= 0.6: return 6.0
        elif percentage >= 0.55: return 5.5
        elif percentage >= 0.5: return 5.0
        elif percentage >= 0.4: return 4.0
        elif percentage >= 0.3: return 3.0
        else: return 2.0

    def calculate_overall_score(self):
        # Calculate overall score as average of all section scores
        scores = [
            self.reading_score or 0,
            self.listening_score or 0,
            self.writing_score or 0,
            self.speaking_score or 0
        ]

        # If speaking is not implemented yet, only average the other scores
        scores = [s for s in scores if s > 0]

        if not scores:
            return 0

        return round(sum(scores) / len(scores) * 2) / 2  # Round to nearest 0.5

    def finalize_results(self):
        """Perform final analysis and generate comprehensive results"""
        # Analyze each section
        self.reading_analysis = self.analyze_reading_performance()
        self.listening_analysis = self.analyze_listening_performance()
        self.writing_analysis = self.analyze_writing_performance()

        # Collect strengths and areas for improvement
        strengths = []
        areas_for_improvement = []

        # Add reading strengths/weaknesses
        if self.reading_analysis:
            strengths.extend(self.reading_analysis.get('strengths', [])[:2])  # Limit to top 2
            areas_for_improvement.extend(self.reading_analysis.get('weaknesses', [])[:2])  # Limit to top 2

        # Add listening strengths/weaknesses
        if self.listening_analysis:
            strengths.extend(self.listening_analysis.get('strengths', [])[:2])  # Limit to top 2
            areas_for_improvement.extend(self.listening_analysis.get('weaknesses', [])[:2])  # Limit to top 2

        # Add writing strengths/weaknesses
        if self.writing_analysis:
            strengths.extend(self.writing_analysis.get('strengths', [])[:2])  # Limit to top 2
            areas_for_improvement.extend(self.writing_analysis.get('weaknesses', [])[:2])  # Limit to top 2

        # Add speaking strengths/weaknesses (placeholder for now)
        if self.speaking_score and self.speaking_score >= 7.0:
            strengths.append("Fluent delivery in speaking")
        elif self.speaking_score and self.speaking_score <= 5.5:
            areas_for_improvement.append("Pronunciation issues in speaking")

        # Save strengths and areas for improvement
        self.strengths = strengths
        self.areas_for_improvement = areas_for_improvement

        # Generate improvement plan
        self.improvement_plan = self.generate_improvement_plan()

        # Save the test
        self.save()

        return {
            'strengths': strengths,
            'areas_for_improvement': areas_for_improvement,
            'improvement_plan': self.improvement_plan
        }

class TestQuestion(models.Model):
    """Model to store individual test questions and user responses"""
    QUESTION_TYPE_CHOICES = (
        ('multiple_choice', 'Multiple Choice'),
        ('true_false_not_given', 'True/False/Not Given'),
        ('matching', 'Matching'),
        ('fill_in_blank', 'Fill in the Blank'),
        ('short_answer', 'Short Answer'),
        ('other', 'Other'),
    )

    SECTION_TYPE_CHOICES = (
        ('reading', 'Reading'),
        ('listening', 'Listening'),
        ('writing', 'Writing'),
        ('speaking', 'Speaking'),
    )

    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    test = models.ForeignKey(MockTest, on_delete=models.CASCADE, related_name='questions')
    section_type = models.CharField(max_length=20, choices=SECTION_TYPE_CHOICES)
    section_number = models.IntegerField()
    question_number = models.IntegerField()
    question_type = models.CharField(max_length=20, choices=QUESTION_TYPE_CHOICES)
    question_text = models.TextField()
    options = models.JSONField(null=True, blank=True)
    correct_answer = models.TextField()
    user_answer = models.TextField(null=True, blank=True)
    is_correct = models.BooleanField(null=True, blank=True)

    class Meta:
        ordering = ['section_type', 'section_number', 'question_number']

    def __str__(self):
        return f"{self.section_type} Q{self.question_number} ({self.test.id})"

    def check_answer(self):
        """Check if the user's answer is correct"""
        if self.user_answer is None:
            self.is_correct = False
        else:
            # Handle both string and non-string answers
            if isinstance(self.user_answer, str) and isinstance(self.correct_answer, str):
                self.is_correct = self.user_answer.lower().strip() == self.correct_answer.lower().strip()
            else:
                # For complex answers like dictionaries, compare string representations
                self.is_correct = str(self.user_answer).lower() == str(self.correct_answer).lower()
        self.save()
        return self.is_correct

class ImprovementPlan(models.Model):
    """Model to store personalized improvement plans"""
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name='improvement_plans')
    test = models.ForeignKey(MockTest, on_delete=models.CASCADE, related_name='improvement_plans', null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    # Plan details
    reading_recommendations = models.JSONField(null=True, blank=True)
    listening_recommendations = models.JSONField(null=True, blank=True)
    writing_recommendations = models.JSONField(null=True, blank=True)
    speaking_recommendations = models.JSONField(null=True, blank=True)
    general_recommendations = models.JSONField(null=True, blank=True)

    # Progress tracking
    is_completed = models.BooleanField(default=False)
    completion_date = models.DateTimeField(null=True, blank=True)

    def __str__(self):
        return f"Improvement Plan for {self.user.username} ({self.created_at.strftime('%Y-%m-%d')})"

    def mark_completed(self):
        """Mark the improvement plan as completed"""
        self.is_completed = True
        self.completion_date = timezone.now()
        self.save()

class WritingPractice(models.Model):
    """Model to store writing practice sessions"""
    TASK_TYPE_CHOICES = (
        ('task1', 'Task 1 - Report'),
        ('task2', 'Task 2 - Essay'),
    )

    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name='writing_practices')
    task_type = models.CharField(max_length=10, choices=TASK_TYPE_CHOICES)
    prompt = models.TextField()
    response = models.TextField(null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    submitted_at = models.DateTimeField(null=True, blank=True)

    # Evaluation scores
    task_achievement = models.FloatField(null=True, blank=True)
    coherence_cohesion = models.FloatField(null=True, blank=True)
    lexical_resource = models.FloatField(null=True, blank=True)
    grammatical_range = models.FloatField(null=True, blank=True)
    overall_score = models.FloatField(null=True, blank=True)

    # Feedback
    feedback = models.JSONField(null=True, blank=True)

    def __str__(self):
        return f"{self.user.username}'s {self.get_task_type_display()} ({self.created_at.strftime('%Y-%m-%d')})"

    def evaluate(self, gpt_service):
        """Evaluate the writing response using GPT"""
        if not self.response:
            return None

        evaluation = gpt_service.evaluate_writing(self.prompt, self.response)

        # Save evaluation scores
        self.task_achievement = evaluation.get('task_achievement', 0)
        self.coherence_cohesion = evaluation.get('coherence_cohesion', 0)
        self.lexical_resource = evaluation.get('lexical_resource', 0)
        self.grammatical_range = evaluation.get('grammatical_range', 0)
        self.overall_score = evaluation.get('overall_score', 0)

        # Save feedback
        self.feedback = evaluation

        # Save submission time
        self.submitted_at = timezone.now()
        self.save()

        return evaluation
